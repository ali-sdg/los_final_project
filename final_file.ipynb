{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPElWmCNtNSmubupWQRhKjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-sdg/los_final_project/blob/main/final_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvaqcE7oWssa"
      },
      "outputs": [],
      "source": [
        "# %% [1] KÃœTÃœPHANELER VE AYARLAR\n",
        "# Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenmesi ve ortam ayarlarÄ±\n",
        "# !pip install shap imbalanced-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shap  # Yorumlanabilirlik iÃ§in (Interpretability)\n",
        "\n",
        "# Google Colab Drive BaÄŸlantÄ±sÄ±\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Scikit-Learn ModÃ¼lleri\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import (classification_report, roc_auc_score, roc_curve,\n",
        "                             confusion_matrix, accuracy_score, precision_recall_curve,\n",
        "                             auc, f1_score, brier_score_loss)\n",
        "\n",
        "# Dengesiz Veri YÃ¶netimi iÃ§in SMOTE (Ã–nemli: Raporda belirtildiÄŸi gibi)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Modelleme AlgoritmalarÄ±\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Grafik AyarlarÄ±\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# %% [2] VERÄ° YÃœKLEME VE Ã–N Ä°ÅžLEME\n",
        "# Veri setinin okunmasÄ± ve temel temizlik iÅŸlemleri\n",
        "FILE_PATH = '/content/drive/MyDrive/Colab Notebooks/final project/MIMIC_ICU_Ultimate_Raw.csv'\n",
        "print(\">>> [1/7] Veri YÃ¼kleniyor ve Ã–n Ä°ÅŸleniyor...\")\n",
        "\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "df = df.dropna(subset=['HeartRate']) # Hayalet kayÄ±tlarÄ±n (Ghost records) temizlenmesi\n",
        "\n",
        "# %% [3] GELÄ°ÅžMÄ°Åž Ã–ZNÄ°TELÄ°K MÃœHENDÄ°SLÄ°ÄžÄ° (CLINICAL FEATURE ENGINEERING)\n",
        "# Raporda belirtilen klinik belirteÃ§lerin ve oranlarÄ±n hesaplanmasÄ±\n",
        "print(\">>> [2/7] Klinik Ã–znitelik MÃ¼hendisliÄŸi YapÄ±lÄ±yor...\")\n",
        "\n",
        "# A. Hemodinamik Ä°ndeksler (Hemodynamic Indices)\n",
        "df['Shock_Index'] = df['HeartRate'] / (df['SysBP'] + 1e-5)\n",
        "df['Pulse_Pressure'] = df['SysBP'] - df['DiasBP']\n",
        "df['Calculated_MAP'] = (df['SysBP'] + (2 * df['DiasBP'])) / 3\n",
        "df['BUN_Creatinine_Ratio'] = df['BUN'] / (df['Creatinine'] + 1e-5)\n",
        "df['Age_CCI_Interaction'] = df['AGE'] * df['CCI_Score']\n",
        "\n",
        "# B. Dinamik Dalgalanmalar (Dynamic Fluctuations)\n",
        "if 'SysBP_Max' in df.columns: df['SysBP_Fluctuation'] = df['SysBP_Max'] - df['SysBP_Min']\n",
        "if 'HeartRate_Max' in df.columns: df['HeartRate_Fluctuation'] = df['HeartRate_Max'] - df['HeartRate_Min']\n",
        "\n",
        "# C. Ä°drar DÃ¶nÃ¼ÅŸÃ¼mleri (Urine Transformations)\n",
        "if 'Urine_Output' in df.columns:\n",
        "    df['Low_Urine_Flag'] = (df['Urine_Output'] < 500).astype(float)\n",
        "    df['Log_Urine'] = np.log1p(df['Urine_Output'].fillna(0))\n",
        "\n",
        "# AykÄ±rÄ± DeÄŸerlerin Temizlenmesi (Outlier Cleaning)\n",
        "df.loc[(df['HeartRate'] < 20) | (df['HeartRate'] > 300), 'HeartRate'] = np.nan\n",
        "df.loc[(df['SysBP'] < 40) | (df['SysBP'] > 300), 'SysBP'] = np.nan\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Hedef DeÄŸiÅŸkenin TanÄ±mlanmasÄ± (Target Definition)\n",
        "THRESHOLD_DAYS = 5\n",
        "df['LOS_Label'] = (df['LOS'] > THRESHOLD_DAYS).astype(int)\n",
        "\n",
        "# %% [4] EKSÄ°K VERÄ° TAMAMLAMA (MICE) VE Ã–LÃ‡EKLENDÄ°RME\n",
        "# Veri setinin modelleme iÃ§in hazÄ±rlanmasÄ±\n",
        "print(\">>> [3/7] MICE ile Eksik Veri Tamamlama ve Ã–lÃ§eklendirme...\")\n",
        "\n",
        "# X ve y ayrÄ±mÄ±\n",
        "meta_cols = ['HADM_ID', 'SUBJECT_ID', 'LOS', 'LOS_Label', 'HOSPITAL_EXPIRE_FLAG', 'CRP']\n",
        "X = df.drop(columns=[c for c in meta_cols if c in df.columns])\n",
        "y = df['LOS_Label']\n",
        "\n",
        "# Ã‡ok seyrek sÃ¼tunlarÄ±n temizlenmesi\n",
        "missing_ratio = X.isnull().mean()\n",
        "X = X.drop(columns=missing_ratio[missing_ratio > 0.40].index)\n",
        "\n",
        "# MICE (Multivariate Imputation by Chained Equations) UygulamasÄ±\n",
        "imputer = IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=10, n_jobs=-1), max_iter=5, random_state=42)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# StandartlaÅŸtÄ±rma (Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
        "\n",
        "# EÄŸitim ve Test Seti AyrÄ±mÄ± (Stratified Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# %% [5] SMOTE VE MODEL EÄžÄ°TÄ°MÄ° (ENSEMBLE LEARNING)\n",
        "# Dengesiz verilerin SMOTE ile dÃ¼zeltilmesi ve Topluluk Modeli eÄŸitimi\n",
        "print(\">>> [4/7] SMOTE UygulanÄ±yor ve Topluluk Modeli EÄŸitiliyor...\")\n",
        "\n",
        "# --- SMOTE UYGULAMASI (Rapora uygun olarak eklendi) ---\n",
        "print(\"    - SMOTE ile Ã¶rneklem artÄ±rma iÅŸlemi...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "print(f\"    - Orijinal EÄŸitim Boyutu: {y_train.shape}, DengelenmiÅŸ EÄŸitim Boyutu: {y_train_bal.shape}\")\n",
        "\n",
        "# Model TanÄ±mlamalarÄ±\n",
        "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.03, max_depth=7,\n",
        "                    subsample=0.8, colsample_bytree=0.7, eval_metric='auc',\n",
        "                    random_state=42, n_jobs=-1)\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(n_estimators=500, learning_rate=0.03, num_leaves=35,\n",
        "                               random_state=42, verbose=-1)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_leaf=2,\n",
        "                            random_state=42, n_jobs=-1)\n",
        "\n",
        "# Voting Ensemble (Oylama SÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±)\n",
        "ensemble = VotingClassifier(estimators=[('xgb', xgb_clf), ('lgb', lgb_clf), ('rf', rf_clf)], voting='soft')\n",
        "\n",
        "# Modeli DENGELENMÄ°Åž (SMOTE uygulanmÄ±ÅŸ) veri Ã¼zerinde eÄŸit\n",
        "ensemble.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Test seti Ã¼zerinde tahmin (OlasÄ±lÄ±klar)\n",
        "y_prob = ensemble.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# %% [6] GÃœVENLÄ°K Ã–NCELÄ°KLÄ° DEÄžERLENDÄ°RME (SAFETY-FIRST STRATEGY)\n",
        "# EÅŸik deÄŸerinin ayarlanmasÄ± ve metriklerin hesaplanmasÄ±\n",
        "print(\">>> [5/7] GÃ¼venlik Ã–ncelikli EÅŸik DeÄŸeri (0.38) UygulanÄ±yor...\")\n",
        "SAFETY_THRESHOLD = 0.38\n",
        "y_pred_safe = (y_prob >= SAFETY_THRESHOLD).astype(int)\n",
        "\n",
        "# --- Metriklerin HesaplanmasÄ± ---\n",
        "cm = confusion_matrix(y_test, y_pred_safe)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "recall_long = tp / (tp + fn)       # DuyarlÄ±lÄ±k (Sensitivity)\n",
        "specificity = tn / (tn + fp)       # Ã–zgÃ¼llÃ¼k (Specificity)\n",
        "precision_long = tp / (tp + fp)\n",
        "f1_long = 2 * (precision_long * recall_long) / (precision_long + recall_long)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "precision_curve_vals, recall_curve_vals, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall_curve_vals, precision_curve_vals)\n",
        "\n",
        "# Ek Metrikler (Appendix)\n",
        "brier = brier_score_loss(y_test, y_prob)\n",
        "f1_macro = f1_score(y_test, y_pred_safe, average='macro')\n",
        "f1_weighted = f1_score(y_test, y_pred_safe, average='weighted')\n",
        "\n",
        "# SONUÃ‡LARIN YAZDIRILMASI\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"      ðŸ“Š BÃ–LÃœM 1: ANA RAPOR SONUÃ‡LARI       \")\n",
        "print(\"=\"*50)\n",
        "results_main = pd.DataFrame({\n",
        "    'Metrik': ['DuyarlÄ±lÄ±k (Sensitivity)', 'Ã–zgÃ¼llÃ¼k (Specificity)', 'F1-Skoru (Uzun KalÄ±ÅŸ)', 'ROC-AUC', 'PR-AUC'],\n",
        "    'DeÄŸer': [recall_long, specificity, f1_long, roc_auc, pr_auc]\n",
        "})\n",
        "print(results_main.to_markdown(index=False, floatfmt=\".4f\"))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"      ðŸ“‚ BÃ–LÃœM 2: EK SONUÃ‡LAR (APPENDIX)       \")\n",
        "print(\"=\"*50)\n",
        "results_appendix = pd.DataFrame({\n",
        "    'Metrik': ['Brier Skoru', 'Makro F1', 'AÄŸÄ±rlÄ±klÄ± F1'],\n",
        "    'DeÄŸer': [brier, f1_macro, f1_weighted]\n",
        "})\n",
        "print(results_appendix.to_markdown(index=False, floatfmt=\".4f\"))\n",
        "\n",
        "# %% [7] GRAFÄ°K Ã‡Ä°ZÄ°MÄ° (VISUALIZATION)\n",
        "# Makale standartlarÄ±na uygun grafiklerin oluÅŸturulmasÄ±\n",
        "print(\">>> [6/7] Grafikler Ã‡iziliyor...\")\n",
        "\n",
        "# ÅžEKÄ°L 1: KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix)\n",
        "# RENK AYARI: Rapordaki Fig. 4 ile eÅŸleÅŸmesi iÃ§in 'Blues' (Mavi) kullanÄ±ldÄ±.\n",
        "plt.figure(figsize=(6, 5))\n",
        "group_names = ['GerÃ§ek Neg','YanlÄ±ÅŸ Poz','YanlÄ±ÅŸ Neg','GerÃ§ek Poz']\n",
        "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names, [\"{0:0.0f}\".format(value) for value in cm.flatten()])]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, annot_kws={\"size\": 12}) # cmap='Blues' olarak gÃ¼ncellendi\n",
        "plt.title(f'GÃ¼venlik Ã–ncelikli KarmaÅŸÄ±klÄ±k Matrisi (EÅŸik={SAFETY_THRESHOLD})', fontsize=14, weight='bold')\n",
        "plt.ylabel('GerÃ§ek Durum')\n",
        "plt.xlabel('Tahmin Edilen Durum')\n",
        "plt.show()\n",
        "\n",
        "# ÅžEKÄ°L 2: ROC ve PR EÄŸrileri\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "ax1.plot(fpr, tpr, color='#2c3e50', lw=3, label=f'Topluluk Modeli (AUC = {roc_auc:.3f})')\n",
        "ax1.plot([0, 1], [0, 1], 'k--')\n",
        "ax1.set_title('ROC EÄŸrisi', weight='bold')\n",
        "ax1.set_xlabel('YanlÄ±ÅŸ Pozitif OranÄ±')\n",
        "ax1.set_ylabel('GerÃ§ek Pozitif OranÄ±')\n",
        "ax1.legend(loc='lower right')\n",
        "# PR - RENK: Rapordaki Fig. 5b ile eÅŸleÅŸmesi iÃ§in Mor (#8e44ad) korundu.\n",
        "ax2.plot(recall_curve_vals, precision_curve_vals, color='#8e44ad', lw=3, label=f'PR-AUC = {pr_auc:.3f}')\n",
        "ax2.set_title('Kesinlik-DuyarlÄ±lÄ±k (PR) EÄŸrisi', weight='bold')\n",
        "ax2.set_xlabel('DuyarlÄ±lÄ±k (Recall)')\n",
        "ax2.set_ylabel('Kesinlik (Precision)')\n",
        "ax2.legend(loc='lower left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ÅžEKÄ°L 3: Kalibrasyon GrafiÄŸi\n",
        "# RENK: Rapordaki Fig. 6 ile eÅŸleÅŸmesi iÃ§in YeÅŸil (#27ae60) korundu.\n",
        "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Topluluk Modeli', color='#27ae60')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='MÃ¼kemmel Kalibrasyon')\n",
        "plt.xlabel('Ortalama Tahmin OlasÄ±lÄ±ÄŸÄ±')\n",
        "plt.ylabel('Pozitiflerin OranÄ±')\n",
        "plt.title('Kalibrasyon GrafiÄŸi', weight='bold')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ÅžEKÄ°L 4: Karar EÄŸrisi Analizi (DCA)\n",
        "# RENK: Rapordaki Fig. 7 ile eÅŸleÅŸmesi iÃ§in KÄ±rmÄ±zÄ± (#e74c3c) korundu.\n",
        "def calculate_net_benefit(y_true, y_prob, thresholds):\n",
        "    net_benefits = []\n",
        "    for thresh in thresholds:\n",
        "        y_pred_thresh = (y_prob >= thresh).astype(int)\n",
        "        tp = np.sum((y_true == 1) & (y_pred_thresh == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred_thresh == 1))\n",
        "        n = len(y_true)\n",
        "        if thresh == 1.0: net_benefit = 0\n",
        "        else: net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
        "        net_benefits.append(net_benefit)\n",
        "    return np.array(net_benefits)\n",
        "\n",
        "thresholds = np.linspace(0.01, 0.99, 100)\n",
        "nb_model = calculate_net_benefit(y_test, y_prob, thresholds)\n",
        "nb_all = calculate_net_benefit(y_test, np.ones_like(y_test), thresholds)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(thresholds, nb_model, label='Ã–nerilen Model', color='#e74c3c', lw=3)\n",
        "plt.plot(thresholds, nb_all, label='Herkese Tedavi Uygula', color='gray', linestyle='--')\n",
        "plt.axhline(y=0, color='black', linestyle='-')\n",
        "plt.ylim(-0.05, 0.6)\n",
        "plt.xlabel('EÅŸik OlasÄ±lÄ±ÄŸÄ±')\n",
        "plt.ylabel('Net Fayda (Net Benefit)')\n",
        "plt.title('Karar EÄŸrisi Analizi (DCA)', weight='bold')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# %% [8] SHAP Ä°LE YORUMLANABÄ°LÄ°RLÄ°K (INTERPRETABILITY)\n",
        "# Modelin kararlarÄ±nÄ± etkileyen faktÃ¶rlerin analizi\n",
        "print(\">>> [7/7] SHAP Analizi OluÅŸturuluyor...\")\n",
        "\n",
        "# Not: Topluluk modelini doÄŸrudan aÃ§Ä±klamak karmaÅŸÄ±ktÄ±r.\n",
        "# Bu nedenle, topluluk iÃ§indeki en gÃ¼Ã§lÃ¼ bileÅŸen (XGBoost) Ã¼zerinden aÃ§Ä±klama yapÄ±yoruz.\n",
        "fitted_xgb = ensemble.estimators_[0]\n",
        "\n",
        "# SHAP Tree Explainer TanÄ±mlanmasÄ±\n",
        "explainer = shap.TreeExplainer(fitted_xgb)\n",
        "# TÃ¼m test seti Ã¼zerinde SHAP deÄŸerlerinin hesaplanmasÄ±\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "# Ã–zellik Ã¶nem sÄ±ralamasÄ± (Åžekil 8 ile uyumlu)\n",
        "shap.summary_plot(shap_values, X_test, show=False)\n",
        "plt.title('SHAP Ã–znitelik Ã–nem DÃ¼zeyi (XGB BileÅŸeni)', fontsize=14, weight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5m4459rWweE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}